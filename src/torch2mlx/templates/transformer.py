"""MLX implementation of standard transformer block.

Covers: multi-head attention + feed-forward network + layer norm,
matching the common PyTorch transformer pattern.
"""

from __future__ import annotations
